{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f68b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import psycopg2\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from psycopg2 import extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35a3502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connection details to localhost\n",
    "HOST='localhost'\n",
    "DBNAME='postgres'\n",
    "USER='postgres'\n",
    "PW='1234'\n",
    "PORT='5433'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3132971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Database\n"
     ]
    }
   ],
   "source": [
    "# initiate connection\n",
    "conn = psycopg2.connect(host=HOST,\n",
    "                        dbname=DBNAME,\n",
    "                        user=USER,\n",
    "                        password=PW,\n",
    "                        port=PORT\n",
    "                        )\n",
    "\n",
    "print(\"Connecting to Database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22253500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute Data Model\n",
    "ur = conn.cursor()\n",
    "DDL = \"\"\"\n",
    "CREATE SCHEMA IF NOT EXISTS instacart;\n",
    "\n",
    "-- Dimensions\n",
    "CREATE TABLE IF NOT EXISTS instacart.user_dim (\n",
    "  user_key     BIGSERIAL PRIMARY KEY,\n",
    "  ext_user_id  INTEGER UNIQUE\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS instacart.department_dim (\n",
    "  department_key BIGSERIAL PRIMARY KEY,\n",
    "  department_id  INTEGER UNIQUE,\n",
    "  department     TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS instacart.aisle_dim (\n",
    "  aisle_key  BIGSERIAL PRIMARY KEY,\n",
    "  aisle_id   INTEGER UNIQUE,\n",
    "  aisle      TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS instacart.product_dim (\n",
    "  product_key    BIGSERIAL PRIMARY KEY,\n",
    "  product_id     INTEGER UNIQUE,\n",
    "  product_name   TEXT,\n",
    "  aisle_key      BIGINT REFERENCES instacart.aisle_dim(aisle_key),\n",
    "  department_key BIGINT REFERENCES instacart.department_dim(department_key)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS instacart.order_dim (\n",
    "  order_key                BIGSERIAL PRIMARY KEY,\n",
    "  order_id                 INTEGER UNIQUE,\n",
    "  user_key                 BIGINT REFERENCES instacart.user_dim(user_key),\n",
    "  order_number             INTEGER,\n",
    "  eval_set                 TEXT,\n",
    "  order_dow                SMALLINT,\n",
    "  order_hour_of_day        SMALLINT,\n",
    "  days_since_prior_order   SMALLINT\n",
    ");\n",
    "\n",
    "-- Fact\n",
    "CREATE TABLE IF NOT EXISTS instacart.fact_order_product (\n",
    "  fact_id            BIGSERIAL PRIMARY KEY,\n",
    "  order_key          BIGINT NOT NULL REFERENCES instacart.order_dim(order_key),\n",
    "  product_key        BIGINT NOT NULL REFERENCES instacart.product_dim(product_key),\n",
    "  add_to_cart_order  SMALLINT,\n",
    "  reordered          SMALLINT\n",
    ");\n",
    "\n",
    "-- Helpful indexes\n",
    "CREATE INDEX IF NOT EXISTS ix_order_user     ON instacart.order_dim(user_key);\n",
    "CREATE INDEX IF NOT EXISTS ix_fact_order     ON instacart.fact_order_product(order_key);\n",
    "CREATE INDEX IF NOT EXISTS ix_fact_product   ON instacart.fact_order_product(product_key);\n",
    "\"\"\"\n",
    "cur.execute(DDL)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75904894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for inserting data faster \n",
    "def execute_values_upsert(insert_sql, rows, page=10000):\n",
    "    if not rows:\n",
    "        return\n",
    "    extras.execute_values(cur, insert_sql, rows, page_size=page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c926aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory of data\n",
    "CSV_DIR = \"data\"\n",
    "\n",
    "PATH_ORDERS         = os.path.join(CSV_DIR, \"orders.csv\")\n",
    "PATH_PRODUCTS       = os.path.join(CSV_DIR, \"products.csv\")\n",
    "PATH_AISLES         = os.path.join(CSV_DIR, \"aisles.csv\")\n",
    "PATH_DEPARTMENTS    = os.path.join(CSV_DIR, \"departments.csv\")\n",
    "PATH_ORDER_PRIOR    = os.path.join(CSV_DIR, \"order_products__prior.csv\")\n",
    "PATH_ORDER_TRAIN    = os.path.join(CSV_DIR, \"order_products__train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7524bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading aisle_dim ...\n",
      "Loading product_dim ...\n",
      "Loading user_dim + order_dim ...\n",
      "  inserted/updated orders rows 0–200,000\n",
      "  inserted/updated orders rows 200,000–400,000\n",
      "  inserted/updated orders rows 400,000–600,000\n",
      "  inserted/updated orders rows 600,000–800,000\n",
      "  inserted/updated orders rows 800,000–1,000,000\n",
      "  inserted/updated orders rows 1,000,000–1,200,000\n",
      "  inserted/updated orders rows 1,200,000–1,400,000\n",
      "  inserted/updated orders rows 1,400,000–1,600,000\n",
      "  inserted/updated orders rows 1,600,000–1,800,000\n",
      "  inserted/updated orders rows 1,800,000–2,000,000\n",
      "  inserted/updated orders rows 2,000,000–2,200,000\n",
      "  inserted/updated orders rows 2,200,000–2,400,000\n",
      "  inserted/updated orders rows 2,400,000–2,600,000\n",
      "  inserted/updated orders rows 2,600,000–2,800,000\n",
      "  inserted/updated orders rows 2,800,000–3,000,000\n",
      "  inserted/updated orders rows 3,000,000–3,200,000\n",
      "  inserted/updated orders rows 3,200,000–3,400,000\n",
      "  inserted/updated orders rows 3,400,000–3,421,083\n",
      "Loading facts from order_products__prior.csv ...\n",
      "  +500,000 rows (total 500,000)\n",
      "  +500,000 rows (total 1,000,000)\n",
      "  +500,000 rows (total 1,500,000)\n",
      "  +500,000 rows (total 2,000,000)\n",
      "  +500,000 rows (total 2,500,000)\n",
      "  +500,000 rows (total 3,000,000)\n",
      "  +500,000 rows (total 3,500,000)\n",
      "  +500,000 rows (total 4,000,000)\n",
      "  +500,000 rows (total 4,500,000)\n",
      "  +500,000 rows (total 5,000,000)\n",
      "  +500,000 rows (total 5,500,000)\n",
      "  +500,000 rows (total 6,000,000)\n",
      "  +500,000 rows (total 6,500,000)\n",
      "  +500,000 rows (total 7,000,000)\n",
      "  +500,000 rows (total 7,500,000)\n",
      "  +500,000 rows (total 8,000,000)\n",
      "  +500,000 rows (total 8,500,000)\n",
      "  +500,000 rows (total 9,000,000)\n",
      "  +500,000 rows (total 9,500,000)\n",
      "  +500,000 rows (total 10,000,000)\n",
      "  +500,000 rows (total 10,500,000)\n",
      "  +500,000 rows (total 11,000,000)\n",
      "  +500,000 rows (total 11,500,000)\n",
      "  +500,000 rows (total 12,000,000)\n",
      "  +500,000 rows (total 12,500,000)\n",
      "  +500,000 rows (total 13,000,000)\n",
      "  +500,000 rows (total 13,500,000)\n",
      "  +500,000 rows (total 14,000,000)\n",
      "  +500,000 rows (total 14,500,000)\n",
      "  +500,000 rows (total 15,000,000)\n",
      "  +500,000 rows (total 15,500,000)\n",
      "  +500,000 rows (total 16,000,000)\n",
      "  +500,000 rows (total 16,500,000)\n",
      "  +500,000 rows (total 17,000,000)\n",
      "  +500,000 rows (total 17,500,000)\n",
      "  +500,000 rows (total 18,000,000)\n",
      "  +500,000 rows (total 18,500,000)\n",
      "  +500,000 rows (total 19,000,000)\n",
      "  +500,000 rows (total 19,500,000)\n",
      "  +500,000 rows (total 20,000,000)\n",
      "  +500,000 rows (total 20,500,000)\n",
      "  +500,000 rows (total 21,000,000)\n",
      "  +500,000 rows (total 21,500,000)\n",
      "  +500,000 rows (total 22,000,000)\n",
      "  +500,000 rows (total 22,500,000)\n",
      "  +500,000 rows (total 23,000,000)\n",
      "  +500,000 rows (total 23,500,000)\n",
      "  +500,000 rows (total 24,000,000)\n",
      "  +500,000 rows (total 24,500,000)\n",
      "  +500,000 rows (total 25,000,000)\n",
      "  +500,000 rows (total 25,500,000)\n",
      "  +500,000 rows (total 26,000,000)\n",
      "  +500,000 rows (total 26,500,000)\n",
      "  +500,000 rows (total 27,000,000)\n",
      "  +500,000 rows (total 27,500,000)\n",
      "  +500,000 rows (total 28,000,000)\n",
      "  +500,000 rows (total 28,500,000)\n",
      "  +500,000 rows (total 29,000,000)\n",
      "  +500,000 rows (total 29,500,000)\n",
      "  +500,000 rows (total 30,000,000)\n",
      "  +500,000 rows (total 30,500,000)\n",
      "  +500,000 rows (total 31,000,000)\n",
      "  +500,000 rows (total 31,500,000)\n",
      "  +500,000 rows (total 32,000,000)\n",
      "  +434,489 rows (total 32,434,489)\n",
      "Loading facts from order_products__train.csv ...\n",
      "  +500,000 rows (total 500,000)\n",
      "  +500,000 rows (total 1,000,000)\n",
      "  +384,617 rows (total 1,384,617)\n"
     ]
    }
   ],
   "source": [
    "# insert data\n",
    "\n",
    "print(\"Loading department_dim ...\")\n",
    "dept = pd.read_csv(PATH_DEPARTMENTS)\n",
    "rows = [(int(r.department_id), str(r.department)) for _, r in dept.iterrows()]\n",
    "execute_values_upsert(\n",
    "    \"\"\"\n",
    "    INSERT INTO instacart.department_dim (department_id, department)\n",
    "    VALUES %s\n",
    "    ON CONFLICT (department_id) DO UPDATE SET department = EXCLUDED.department;\n",
    "    \"\"\",\n",
    "    rows\n",
    ")\n",
    "conn.commit()\n",
    "\n",
    "print(\"Loading aisle_dim ...\")\n",
    "ais = pd.read_csv(PATH_AISLES)\n",
    "rows = [(int(r.aisle_id), str(r.aisle)) for _, r in ais.iterrows()]\n",
    "execute_values_upsert(\n",
    "    \"\"\"\n",
    "    INSERT INTO instacart.aisle_dim (aisle_id, aisle)\n",
    "    VALUES %s\n",
    "    ON CONFLICT (aisle_id) DO UPDATE SET aisle = EXCLUDED.aisle;\n",
    "    \"\"\",\n",
    "    rows\n",
    ")\n",
    "conn.commit()\n",
    "\n",
    "# -----------------------------\n",
    "# Load product_dim\n",
    "# -----------------------------\n",
    "print(\"Loading product_dim ...\")\n",
    "prod = pd.read_csv(PATH_PRODUCTS)\n",
    "prod_rows = []\n",
    "for _, r in prod.iterrows():\n",
    "    ak = aisle_map.get(int(r.aisle_id))\n",
    "    dk = dept_map.get(int(r.department_id))\n",
    "    prod_rows.append((int(r.product_id), str(r.product_name), ak, dk))\n",
    "\n",
    "execute_values_upsert(\n",
    "    \"\"\"\n",
    "    INSERT INTO instacart.product_dim (product_id, product_name, aisle_key, department_key)\n",
    "    VALUES %s\n",
    "    ON CONFLICT (product_id) DO UPDATE\n",
    "      SET product_name = EXCLUDED.product_name,\n",
    "          aisle_key = EXCLUDED.aisle_key,\n",
    "          department_key = EXCLUDED.department_key;\n",
    "    \"\"\",\n",
    "    prod_rows\n",
    ")\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Load user_dim and order_dim\n",
    "# -----------------------------\n",
    "print(\"Loading user_dim + order_dim ...\")\n",
    "orders = pd.read_csv(PATH_ORDERS)\n",
    "\n",
    "# user_dim\n",
    "user_ids = sorted(orders[\"user_id\"].dropna().astype(int).unique().tolist())\n",
    "user_rows = [(uid,) for uid in user_ids]\n",
    "execute_values_upsert(\n",
    "    \"\"\"\n",
    "    INSERT INTO instacart.user_dim (ext_user_id)\n",
    "    VALUES %s\n",
    "    ON CONFLICT (ext_user_id) DO NOTHING;\n",
    "    \"\"\",\n",
    "    user_rows\n",
    ")\n",
    "conn.commit()\n",
    "\n",
    "ORDER_CHUNK = 200_000\n",
    "for i in range(0, len(orders), ORDER_CHUNK):\n",
    "    chunk = orders.iloc[i:i+ORDER_CHUNK].copy()\n",
    "    rows = []\n",
    "    for _, r in chunk.iterrows():\n",
    "        uk = user_map.get(int(r.user_id))\n",
    "        rows.append((\n",
    "            int(r.order_id),\n",
    "            uk,\n",
    "            int(r.order_number) if not pd.isna(r.order_number) else None,\n",
    "            str(r.eval_set),\n",
    "            int(r.order_dow) if not pd.isna(r.order_dow) else None,\n",
    "            int(r.order_hour_of_day) if not pd.isna(r.order_hour_of_day) else None,\n",
    "            int(r.days_since_prior_order) if not pd.isna(r.days_since_prior_order) else None\n",
    "        ))\n",
    "    execute_values_upsert(\n",
    "        \"\"\"\n",
    "        INSERT INTO instacart.order_dim\n",
    "          (order_id, user_key, order_number, eval_set, order_dow, order_hour_of_day, days_since_prior_order)\n",
    "        VALUES %s\n",
    "        ON CONFLICT (order_id) DO UPDATE\n",
    "          SET user_key = EXCLUDED.user_key,\n",
    "              order_number = EXCLUDED.order_number,\n",
    "              eval_set = EXCLUDED.eval_set,\n",
    "              order_dow = EXCLUDED.order_dow,\n",
    "              order_hour_of_day = EXCLUDED.order_hour_of_day,\n",
    "              days_since_prior_order = EXCLUDED.days_since_prior_order;\n",
    "        \"\"\",\n",
    "        rows\n",
    "    )\n",
    "    conn.commit()\n",
    "    print(f\"  inserted/updated orders rows {i:,}–{min(i+ORDER_CHUNK, len(orders)):,}\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Load fact_order_product (prior + train)\n",
    "# -----------------------------\n",
    "def load_order_products(path):\n",
    "    print(f\"Loading facts from {os.path.basename(path)} ...\")\n",
    "    chunksize = 500_000\n",
    "    reader = pd.read_csv(path, chunksize=chunksize)\n",
    "    total = 0\n",
    "    for chunk in reader:\n",
    "        rows = []\n",
    "        for _, r in chunk.iterrows():\n",
    "            ok = order_map.get(int(r.order_id))\n",
    "            pk = prod_map.get(int(r.product_id))\n",
    "            if ok is None or pk is None:\n",
    "                continue\n",
    "            rows.append((\n",
    "                ok,\n",
    "                pk,\n",
    "                int(r.add_to_cart_order) if not pd.isna(r.add_to_cart_order) else None,\n",
    "                int(r.reordered) if not pd.isna(r.reordered) else None\n",
    "            ))\n",
    "        execute_values_upsert(\n",
    "            \"\"\"\n",
    "            INSERT INTO instacart.fact_order_product\n",
    "              (order_key, product_key, add_to_cart_order, reordered)\n",
    "            VALUES %s\n",
    "            ON CONFLICT DO NOTHING;\n",
    "            \"\"\",\n",
    "            rows\n",
    "        )\n",
    "        conn.commit()\n",
    "        total += len(rows)\n",
    "        print(f\"  +{len(rows):,} rows (total {total:,})\")\n",
    "S\n",
    "load_order_products(PATH_ORDER_PRIOR)\n",
    "load_order_products(PATH_ORDER_TRAIN)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
